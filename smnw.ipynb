{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy.random as rnd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn.utils as shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import backend as K\n",
    "from keras.regularizers  import l2\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Dense, Flatten, merge, Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/rishigarg/opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/rishigarg/opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def w_init (shape, dtype, name = None):\n",
    "    values = rnd.normal(loc = 0, scale = 1e-2, size  = shape)\n",
    "    return K.variable(values, name = name, dtype = dtype)\n",
    "\n",
    "def b_init (shape, dtype, name = None):\n",
    "    values = rnd.normal(loc = 0.5, scale = 1e-2, size = shape)\n",
    "    return K.variable(values, name = name, dtype = dtype)\n",
    "\n",
    "input_shape = (98, 98, 1)\n",
    "left_input = Input(input_shape)\n",
    "right_input = Input(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "siamnet = Sequential()\n",
    "siamnet.add(Conv2D(64, (10, 10), activation = \"relu\", input_shape = input_shape))\n",
    "\n",
    "siamnet.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "siamnet.add(Conv2D(128, (7, 7), activation =\"relu\"))\n",
    "\n",
    "siamnet.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "siamnet.add(Conv2D(128, (4, 4), activation =\"relu\"))\n",
    "\n",
    "siamnet.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "siamnet.add(Conv2D(256, (4, 4), activation =\"relu\"))\n",
    "\n",
    "siamnet.add(Flatten())\n",
    "\n",
    "siamnet.add(Dense(4096, activation = \"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/rishigarg/opt/anaconda3/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/rishigarg/opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/rishigarg/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "27417409"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "encoded_left = siamnet(left_input)\n",
    "encoded_right = siamnet(right_input)\n",
    "\n",
    "L1_siamese = Lambda(lambda tensors:K.abs(tensors[0] - tensors[1]))\n",
    "L1_dist = L1_siamese([encoded_left, encoded_right])\n",
    "\n",
    "similarity = Dense(1, activation = \"sigmoid\")(L1_dist)\n",
    "\n",
    "siamese_network = Model(inputs = [left_input, right_input], outputs = similarity)\n",
    "\n",
    "siamese_network.compile(loss = \"binary_crossentropy\", optimizer = Adam(0.00006))\n",
    "\n",
    "siamese_network.count_params()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 2\n",
    "sample_size = 5000  \n",
    "\n",
    "def prepare_data(size, sample_size):\n",
    "    count = 0\n",
    "    path = []\n",
    "    image_pairs = []\n",
    "    targets =  []\n",
    "    \n",
    "    dim1 = 98\n",
    "    dim2 = 98\n",
    "    img_pair = np.zeros([sample_size, 2, dim1, dim2])\n",
    "    trgt = np.zeros([sample_size, 1])\n",
    "    \n",
    "    for fx in os.listdir('data'):\n",
    "        filepath = 'data/' + fx\n",
    "        path.append(fx)\n",
    "        for j in range(int(sample_size/152)):\n",
    "            index1 = 0\n",
    "            index2 = 0\n",
    "        \n",
    "            while index1 == index2:\n",
    "                index1 = np.random.randint(20)\n",
    "                index2 = np.random.randint(20)\n",
    "                \n",
    "            image1 = cv2.imread(filepath + '/' + fx + '.' + str(index1 + 1) + '.jpg')\n",
    "            image2 = cv2.imread(filepath + '/' + fx + '.' + str(index2 + 1) + '.jpg')\n",
    "            \n",
    "            gray1 = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)\n",
    "            gray2 = cv2.cvtColor(image2, cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "            gray1 = gray1[::size, ::size]\n",
    "            gray2 = gray2[::size, ::size]\n",
    "                        \n",
    "            img_pair[count, 0, :, :] = gray1\n",
    "            img_pair[count, 1, :, :] = gray2\n",
    "            \n",
    "            trgt[count] = 1\n",
    "\n",
    "            count += 1\n",
    "        \n",
    "    count = 0\n",
    "\n",
    "    imgImposite_pair = np.zeros([sample_size, 2, dim1, dim2])\n",
    "    trgtImposite = np.zeros([sample_size, 1])\n",
    "    \n",
    "    for i in range(int(sample_size/20)):\n",
    "        for j in range(20):\n",
    "            index1 = 0\n",
    "            index2 = 0\n",
    "            \n",
    "            while index1 == index2:\n",
    "                index1 = np.random.randint(40)\n",
    "                index2 = np.random.randint(40)\n",
    "                \n",
    "            image1 = cv2.imread('data/' + path[index1] + '/' +path[index1] + '.' + str(j+1) + '.jpg')\n",
    "            image2 = cv2.imread('data/' + path[index2] + '/' +path[index2] + '.' + str(j+1) + '.jpg')\n",
    "            \n",
    "            gray1 = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)\n",
    "            gray2 = cv2.cvtColor(image2, cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "            gray1 = gray1[::size, ::size]\n",
    "            gray2 = gray2[::size, ::size]\n",
    "    \n",
    "            imgImposite_pair[count, 0, :, :] = gray1\n",
    "            imgImposite_pair[count, 1, :, :] = gray2\n",
    "            \n",
    "            trgtImposite[count] = 0\n",
    "            \n",
    "            count += 1\n",
    "\n",
    "    image_pairs = np.concatenate([img_pair, imgImposite_pair], axis=0)/255\n",
    "    targets = np.concatenate([trgt, trgtImposite], axis=0)\n",
    "    \n",
    "    return image_pairs, targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_pairs, targets = prepare_data(size, sample_size)\n",
    "\n",
    "no_of_sample = image_pairs.shape[0]\n",
    "pairs = image_pairs.shape[1]\n",
    "img_rows = image_pairs[0][0].shape[0]\n",
    "img_cols = image_pairs[0][0].shape[1]\n",
    "\n",
    "Image_pairs = image_pairs.reshape(no_of_sample, pairs, img_rows, img_cols, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/rishigarg/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/compat/v2_compat.py:68: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rishigarg/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:12: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5625 samples, validate on 1875 samples\n",
      "Epoch 1/10\n",
      " - 383s - loss: 0.5180 - val_loss: 0.4126\n",
      "Epoch 2/10\n",
      " - 409s - loss: 0.3282 - val_loss: 0.2755\n",
      "Epoch 3/10\n",
      " - 445s - loss: 0.2264 - val_loss: 0.2253\n",
      "Epoch 4/10\n",
      " - 462s - loss: 0.1697 - val_loss: 0.1819\n",
      "Epoch 5/10\n",
      " - 436s - loss: 0.1314 - val_loss: 0.1412\n",
      "Epoch 6/10\n",
      " - 456s - loss: 0.0992 - val_loss: 0.1271\n",
      "Epoch 7/10\n",
      " - 509s - loss: 0.0818 - val_loss: 0.1149\n",
      "Epoch 8/10\n",
      " - 507s - loss: 0.0671 - val_loss: 0.1042\n",
      "Epoch 9/10\n",
      " - 550s - loss: 0.0583 - val_loss: 0.0994\n",
      "Epoch 10/10\n",
      " - 437s - loss: 0.0528 - val_loss: 0.0969\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "tr_imgPairs, ts_imgPairs, tr_targets, ts_targets = train_test_split(Image_pairs, targets, \n",
    "                                                                    test_size = 0.25, \n",
    "                                                                    random_state = 0)\n",
    "\n",
    "image1 = tr_imgPairs[:, 0]\n",
    "image2 = tr_imgPairs[:, 1]\n",
    "\n",
    "siamese_network.fit([image1, image2], tr_targets, validation_split=.25, batch_size=128, verbose=2, \n",
    "                    nb_epoch = 10)\n",
    "\n",
    "pred = siamese_network.predict([ts_imgPairs[:, 0], ts_imgPairs[:, 1]])\n",
    "\n",
    "def compute_accuracy(predictions, labels):\n",
    "    return labels[predictions.ravel()] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 98, 98, 1)\n"
     ]
    }
   ],
   "source": [
    "test_image1 = cv2.imread('9540636.8' + '.jpg')\n",
    "test_image2 = cv2.imread('9540504.2' + '.jpg')\n",
    "\n",
    "gray1 = cv2.cvtColor(test_image1, cv2.COLOR_BGR2GRAY)\n",
    "gray2 = cv2.cvtColor(test_image2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "gray1 = gray1[::size, ::size]\n",
    "gray2 = gray2[::size, ::size]\n",
    "\n",
    "gray1 = gray1.reshape(1,98,98,1)\n",
    "gray2 = gray2.reshape(1,98,98,1)\n",
    "\n",
    "print(gray2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9775519]]\n"
     ]
    }
   ],
   "source": [
    "pred = siamese_network.predict([gray1,gray2])\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82.32\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_network.save(\"my_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9775519]]\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "new_model = load_model(\"my_model.h5\")\n",
    "pred = new_model.predict([gray1,gray2])\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7500/7500 [==============================] - 143s 19ms/step\n"
     ]
    }
   ],
   "source": [
    "score = new_model.evaluate([tr_imgPairs[:, 0], tr_imgPairs[:, 1]], tr_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.057816594038407006\n"
     ]
    }
   ],
   "source": [
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 49s 20ms/step\n",
      "0.09393809925317764\n"
     ]
    }
   ],
   "source": [
    "score = new_model.evaluate([ts_imgPairs[:, 0], ts_imgPairs[:, 1]], ts_targets)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
